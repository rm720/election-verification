\chapter{Background}


\section{Overview}
\begin{itemize}
\item \textbf{Tools} that we discuss are used to develop proven correct software. Proof assistants, such as HOL4, can be used to write mathematical proofs about the code, and help verifying the correctness of election software. CakeML is a programming language that can be used to compile correctly operating programs.

\item \textbf{Algebra} is used to understand the underlying mathematics of cryptography. Abelian groups, fields, cyclic groups, and discrete logarithms are all important concepts in cryptography.

\item \textbf{Cryptography} is used to protect electronic elections. Zero knowledge proofs, sigma protocols, and the Schnorr protocol and other are all cryptographic techniques that are useful for electronic elections.

\item \textbf{Electronic Elections} are the application of cryptography and other technologies to the voting process. Helios Voting is an example of an electronic election system. The IACR 2022 Director Election conducted with Helios is an example of a real election that we use for our project.
\end{itemize}

These concepts are all interconnected. Proof assistants are used to verify the correctness of election related software, which is written in a verified programming  language like CakeML. Algebra essentials, such as groups and fields, are used to understand the underlying mathematics of cryptography. Cryptography is used to secure electronic elections, which are deployed via systems like Helios Voting. 


\section{Tools}
\subsection{Proof Assistants}

A proof assistant is a software tool, akin to a programming language, specifically designed for writing and structuring mathematical proofs. While it doesn't automate the proof process entirely, a proof assistant can streamline some of the more routine, tedious tasks associated with constructing proofs.

Primarily, proof assistants offer an extensive library of standard mathematical theories and tactics. These libraries facilitate easy search of theorems by formal parameters, along with a suite of specialised tools available to proof developers. The formalisation of mathematical theories through proof assistants is a currently thriving research area within the realm of formal logic.

The objectives for constructing formal proofs can greatly vary. For instance, in mathematics, proof assistants are used to reduce labor-intensive tasks such as exhaustive case analysis. In the field of software development, proof assistants are utilised to verify certain properties of code, such as compliance with a given specification. This allows developers to simultaneously develop and prove the code according to clearly defined correctness criteria, which significantly bolsters confidence in the code's correct operation.

However, it's important to note that the use of proof assistants is not a common practice in general software development. The reason being, working with proof assistants necessitates a solid understanding of logic and mathematical proofs, thereby presenting a steep learning curve. Additionally, the requirement to develop proofs alongside the working code can result in higher labor hours. These factors contribute to a higher cost of development.

Consequently, proof-based software development is mostly employed in critical areas where the cost of a software operation error could be exceedingly high. These sectors include, but are not limited to, aerospace and cryptography.\\

It's crucial to understand that a proof of code correctness doesn't inherently ensure the correct execution of a program. As outlined in the introductory chapter, there exists a gap in software correctness. Both the compiler and the proof assistant's code need to be verified for correctness of program operation.

Notably, not all proof assistants have their own code verified, nor do they necessarily have the compiler's code verified. This state of non-verification isn't inherently problematicâ€”it largely depends on the specific objectives of the proof assistant.

For instance, LEAN\footnote{https://leanprover.github.io} operates on the principle of peer review by numerous advanced mathematicians, with no immediate plans for formal verification of its code. On the other hand, the HOL4\footnote{https://hol-theorem-prover.org} proof assistant has undergone formal verification using an intricate self-verification technique, which will be discussed in more detail later. The distinction in approaches reflects the diverse range of applications and methodologies in the field of proof assistants.

\subsection{HOL4}
HOL4 is a proof assistant and automatic theorem prover. HOL stands for Higher Order Logic, number 4 stands for version number. This software generates an interactive proof writing environment called HOL. This name is the same as the name of area of mathematics. In this work we will use word \text{``HOL"} without version number for software and environment, and make it clear by the context which one of those we refer to. In many cases, when we have a high level discussion we do not need to differentiate them. 

Higher-order logic is a form of predicate logic that allows quantification not only over individual variables but also over function and predicate symbols. This is in contrast to first-order logic, which only allows quantification over individual variables.\\
In first-order logic, we can make statements similar to \\
"For all \textbf{x}, \textbf{P(x)}" or ``There exists an \textbf{x} such that \textbf{P(x)}", \\
where \textbf{P} is a predicate and \textbf{x} is a variable that ranges over individuals in our domain of discourse.\\
Higher-order logic extends this by allowing we to make statements similar to\\
"For all functions \textbf{f}, \textbf{P(f)}" or ``There exists a predicate \textbf{P} such that \textbf{Q(P)}", \\
where \textbf{f} is a function symbol, \textbf{P} and \textbf{Q} are predicates, and we're quantifying over all possible functions or predicates in our domain.\\
HOL employs StandardML as its internal programming language. The typical proof construction process in HOL proceeds as follows:\\
Initially, the user formulates the goal as a theorem. Subsequently, they progress incrementally, either advancing from the premise towards the conclusion, or vice versa. Each step in this process is accomplished by invoking a specific theorem or a combination thereof.\\
However, in practice, the application of theorems can vary, which necessitates the user to define a specific tactic. A tactic represents the strategy for theorem application.\\
\newpage
\subsection{HOL4 Tutorial}
To illustrate this, consider the following simple example from the official HOL tutorial \cite{HOL4interaction}. Additional explanation can be found in the description manual \cite{hol4manual}.
\begin{verbatim}
open arithmeticTheory listTheory;

Theorem less_eq_mult:
  for all n:num. n <= n * n
Proof
    Induct_on n>-
    decide_tac >-
    (asm_simp_tac bool_ss [MULT]>>
        decide_tac)
QED
\end{verbatim}

The theorem we want to prove states that for any natural number $\mathbf{n}$, $\mathbf{n}$ is less than or equal to $\mathbf{n} * \mathbf{n}$. The proof of this theorem is carried out interactively with the use of tactics. We run the code line by line. 

First, we import the required theories: arithmetic theory and list theory. Then, we set the goal to prove. We want to use induction on $\mathbf{n}$ so we apply the induction tactic in relation to variable $\mathbf{n}$.

The induction tactic transforms the goal from one to two subgoals:

\begin{itemize}
    \item Base case:  $0 \leq 0 \times 0$,
    \item Step case: $(n+1) \leq (n+1) \times (n+1)$.
\end{itemize}

Then, we apply the \texttt{decide\_tac} tactic. 
This tactic in HOL is a decision procedure tactic. A decision procedure is an algorithm that can definitively answer specific kinds of questions. In the context of a theorem prover like HOL, a decision procedure is used to determine whether certain classes of statements are true or false.
This resolves the base case. And we are left with one goal to prove step case. 

Next we apply tactics \textbf{\texttt{asm\_sim\_tac}}. This is a simplification tactic that uses both the given simpset and the current assumptions to simplify the goal.

A simpset, short for simplification set, is a collection of theorems that the simplifier uses to rewrite terms. The term \texttt{bool\_ss} in our example is a simpset that includes basic simplification rules for boolean algebra.

Simplification is a commonly used tactic in interactive theorem proving. It works by applying equalities in a way that attempts to simplify the goal, often by rewriting complex expressions into simpler ones, or even solving the goal entirely if possible.

The \texttt{asm\_simp\_tac} tactic is called with a simpset and a list of theorems, and it tries to simplify the goal by repeatedly applying these theorems, as well as the assumptions of the current goal.

So in the context of our proof, \texttt{asm\_simp\_tac bool\_ss [MULT]} is trying to simplify the goal using the theorems in \texttt{bool\_ss} and the \texttt{MULT} theorem, as well as the assumptions of the current goal.

We provide the tactic \texttt{asm\_simp\_tac} with the parameter \texttt{bool\_ss}. Additionally, we supply \texttt{bool\_ss} with a list containing a single theorem, \texttt{[MULT]}.

Where \texttt{MULT} is a theorem defined as follows:
\begin{flushleft}
\texttt{MULT = $\vdash$ ($\forall$n. 0 $\times$ n = 0) $\land$ $\forall$m n. SUC m $\times$ n = m $\times$ n + n: thm}
\end{flushleft}

\texttt{bool\_ss} refers to a simpset - a collection of theorems - that is used by the simplifier to rewrite terms. The simpset \texttt{bool\_ss} contains basic simplification rules for boolean algebra. These rules can be used by the \texttt{asm\_simp\_tac} tactic to simplify the goal during the proof process. 

In other words, \texttt{bool\_ss} provides the \texttt{asm\_simp\_tac} tactic with the rules it needs to try and simplify or solve the goal. These rules include identities and equivalences from boolean algebra that can be used to rewrite boolean expressions into simpler or equivalent forms.

Altogether, \texttt{asm\_simp\_tac bool\_ss [MULT]} is a call to the simplification tactic \texttt{asm\_simp\_tac} with the simpset \texttt{bool\_ss} and the theorems in the list \texttt{[MULT]}. 

Here, \texttt{MULT} is a theorem stating the properties of multiplication involving zero and the successor function (essentially defining how multiplication works for natural numbers in a recursive manner). It is used as an argument to the \texttt{asm\_simp\_tac} simplification tactic.

\texttt{asm\_simp\_tac bool\_ss [MULT]} instructs HOL4 to simplify the current goal using the theorems included in \texttt{bool\_ss} (which covers basic boolean algebra rules) and the multiplication theorem \texttt{MULT}. 

The simplifier will use these rules to attempt to rewrite and simplify the goal, which could involve reducing complex expressions into simpler forms or even solving the goal entirely if possible. The \texttt{asm\_simp\_tac} tactic also takes into account the current assumptions of the goal for the simplification.

Then, we again apply the \textbf{\texttt{decide\_tac}} tactic. This tactic is used to decide a goal that can be solved directly by existing facts or theorems. Applying this tactic simplifies our problem and leads us to the proof of the subgoal:

\begin{flushleft}
\textbf{\texttt{Goal proved: [.] $\vdash$ SUC n $\leq$ n $\times$ SUC n + SUC n}}
\end{flushleft}

This shows that $n+1$ is less than or equal to $n \times (n+1) + (n+1)$, which is a crucial step in our induction.

Following that, we prove the previous goal:

\begin{flushleft}
\textbf{\texttt{Goal proved: [.] $\vdash$ SUC n $\leq$ SQ(SUC n)}}
\end{flushleft}

This shows that $n+1$ is less than or equal to the square of $n+1$.

With these steps completed, we have proved our initial goal:

\begin{flushleft}
\textbf{\texttt{val it =}}\\
\textbf{\texttt{Initial goal proved: $\vdash$ $\forall$ n. n $\leq$ SQ(n): proof}}
\end{flushleft}

This confirms that for all natural numbers $n$, $n$ is less than or equal to the square of $n$.

\subsection{CakeML}
CakeML\footnote{https://cakeml.org} is a functional programming language and an ecosystem of proofs and tools built around it. It is a variant of the ML (Meta Language) family, which also includes languages such as Standard ML and OCaml. One of the distinctive features of CakeML is that it has a formally verified compiler \cite{Tan2019TheVC}, meaning that the compiler's behavior has been proven mathematically to adhere to the language's specification.

CakeML is designed with an emphasis on verifiability, robustness, and performance. It supports a range of programming constructs, including first-class functions, user-defined datatypes, pattern-matching, and mutable reference cells.

The CakeML ecosystem includes a formally verified compiler backend, a logic model of the language semantics, and a growing set of libraries and tools. The verified compiler backend provides strong guarantees about the correctness of compiled code. The logic model can be used to reason about CakeML programs within HOL4 proof assistant. The libraries and tools offer various facilities for developing and working with CakeML programs.

Currently, CakeML is an active project with ongoing research and development.

\subsection{Self-verification} 


The HOL4 theorem prover and the CakeML compiler have both been subject to rigorous formal verification processes to ensure their correctness \cite{Myreen2013StepsTV, Harrison2006TowardsSO, Abrahamsson2022CandleAV}, Result is a guarantee that HOL4 can only generate valid proofs, and that programs compiled with CakeML behave precisely as specified by their source code. This robust level of assurance is achieved through a techniques known as self-verification and self-formalisation  \cite{Kumar2016SelfFormalisationOH}. 

There is no magic here, system cannot be verified within itself as it contradicts to Goedel Second Incompleteness Theorem \cite{Gdel1966OnFU}. The trick is to ultimately reduce the initial (trusted) code base and manually verify these few lines of code. Then the rest of the code relies on this correctness.

The self-verification process employs a approach called bootstrapping and the concept of a small trusted code base, also referred to as a Trusted Code Base (TCB). This approach is fundamental to the development of both the HOL4 and CakeML systems, and is widely used in the creation of verified systems. By maintaining a small TCB and applying formal verification to the components within it, the integrity and correctness of the entire system can be assured.

HOL4 implements environment HOL. HOL4 is a theorem prover for Higher Order Logic (HOL). Its kernel, which forms the trusted code base (TCB), is written in a way that facilitates review and validation for correctness. The kernel is capable of checking proofs about more complex aspects of the system. Much of HOL4 is written in HOL itself, making it subject to verification by the HOL4 kernel.

The compiler for CakeML can be implemented as a function in is written in HOL. A proof within the HOL4 environment demonstrates that the compiler correctly follows the semantics of the CakeML language. This proof, combined with the HOL4 kernel, forms the TCB for CakeML.

Through these steps, the verification of both the HOL4 theorem prover and the CakeML compiler is achieved. This process uses a minimal TCB to ensure trust in the system, and leverages bootstrapping to build up verified layers of the system.

There is work on make it even better and give a more rigorous proof of correctness of HOL environment.
HOL is an interactive environment with its rules, properties and attributes. HOL4 implements HOL environment, but other implementations of HOL can exist. In order to prove that HOL-type environment produces only valid proofs some people implement a kernel of HOL-theorem prover using CakeML programming language \cite{Abrahamsson2022CandleAV, Kumar2014HOLWD}. This kernel of HOL theorem prover. Using bootstrapping this kernel verifies the rest of the HOL system, and implements new HOL environment. This new HOL environment is not the same HOL environment implemented by HOL4 but features the same general system parameters. 

The current state is that HOL4 correctness relies on tiny trusted code base which was thoroughly reviewed. CakeML compiler correctness relies on its implementation in HOL environment. 
There are other HOL environment that are generated by the kernel compiled by CakeML, which is implemented in (another) HOL environment. 

\section{Algebra essentials}
We used the Algebra textbook for definitions in this section\cite{Artin:1998}.

\subsection{Group}
A group is a set $\mathbf{G}$ equipped with a binary operation $\cdot$ (called the group operation) that satisfies the following axioms: \\
Closure: For all $\mathbf{g,h} \in \mathbf{G}$, $\mathbf{g} \cdot \mathbf{h} \in \mathbf{G}$. \\ 
Associativity: For all $\mathbf{g,h,k} \in \mathbf{G}$, $(\mathbf{g} \cdot \mathbf{h}) \cdot \mathbf{k} = \mathbf{g} \cdot (\mathbf{h} \cdot \mathbf{k})$. \\ 
Identity element: There exists an element $\mathbf{e} \in \mathbf{G}$ such that for all $\mathbf{g} \in \mathbf{G}$, $\mathbf{e} \cdot \mathbf{g} = \mathbf{g} \cdot \mathbf{e} = \mathbf{g}$. \\ 
Inverse element: For each $\mathbf{g} \in \mathbf{G}$, there exists an element $\mathbf{g^{-1}} \in \mathbf{G}$ \\ 
such that $\mathbf{g} \cdot \mathbf{g^{-1}} = \mathbf{g^{-1}} \cdot \mathbf{g} = \mathbf{e}$. 

\subsection{Abelian Group}
An Abelian group, also known as a commutative group, is a group $(\mathbf{G}, \cdot)$ in which the group operation is commutative, that is, for all $\mathbf{g,h} \in \mathbf{G}$, we have $\mathbf{g} \cdot \mathbf{h} = \mathbf{h} \cdot \mathbf{g}$. In other words, the order of the elements in operation does not matter.


\subsection{Field}
A field is a set $\mathbf{F}$ equipped with two binary operations, denoted by $+$ and $\cdot$, which satisfy the following axioms:

\begin{enumerate}
\item $(\mathbf{F},+)$ is an Abelian group with identity element 0, i.e., for all $\mathbf{a,b,c} \in \mathbf{F}$,
\begin{enumerate}
\item Associativity: $\mathbf{a}+( \mathbf{b}+\mathbf{c}) = (\mathbf{a}+\mathbf{b})+\mathbf{c}$.
\item Commutativity: $\mathbf{a}+\mathbf{b} = \mathbf{b}+\mathbf{a}$.
\item Identity: There exists an element 0 in $\mathbf{F}$ such that $\mathbf{a}+0 = \mathbf{a}$ for all $\mathbf{a} \in \mathbf{F}$.
\item Inverse: For every $\mathbf{a} \in \mathbf{F}$, there exists an element $-\mathbf{a} \in \mathbf{F}$ such that $\mathbf{a}+(-\mathbf{a}) = (-\mathbf{a})+\mathbf{a} = 0$.
\end{enumerate}
\item $(\mathbf{F}\setminus{0},\cdot)$ is an Abelian group with identity element 1, i.e., for all $\mathbf{a,b,c} \in \mathbf{F}\setminus{0}$,
\begin{enumerate}
\item Associativity: $\mathbf{a}\cdot (\mathbf{b}\cdot \mathbf{c}) = (\mathbf{a}\cdot \mathbf{b})\cdot \mathbf{c}$.
\item Commutativity: $\mathbf{a}\cdot \mathbf{b} = \mathbf{b}\cdot \mathbf{a}$.
\item Identity: There exists an element 1 in $\mathbf{F}\setminus{0}$ such that $\mathbf{a}\cdot 1 = \mathbf{a}$ for all $\mathbf{a} \in \mathbf{F}\setminus{0}$.
\item Inverse: For every $\mathbf{a} \in \mathbf{F}\setminus{0}$, there exists an element $\mathbf{a}^{-1} \in \mathbf{F}\setminus{0}$ such that $\mathbf{a}\cdot \mathbf{a}^{-1} = \mathbf{a}^{-1}\cdot \mathbf{a} = 1$.
\end{enumerate}
\item The distributive laws hold, i.e., for all $\mathbf{a,b,c} \in \mathbf{F}$,
\begin{enumerate}
\item Left distributivity: $\mathbf{a}\cdot(\mathbf{b}+\mathbf{c}) = \mathbf{a}\cdot \mathbf{b} + \mathbf{a}\cdot \mathbf{c}$.
\item Right distributivity: $(\mathbf{a}+\mathbf{b})\cdot \mathbf{c} = \mathbf{a}\cdot \mathbf{c} + \mathbf{b}\cdot \mathbf{c}$.
\end{enumerate}
\end{enumerate}

\subsection{Cyclic Group}
A group $(\mathbf{G}, \cdot)$ is called a cyclic group if there exists an element $\mathbf{g} \in \mathbf{G}$ such that for every element $\mathbf{x} \in \mathbf{G}$, there exists an integer $\mathbf{n}$ such that $\mathbf{x} = \mathbf{g}^\mathbf{n}$. In other words, every element of the group can be obtained by repeatedly applying the group operation to a single element, called a generator.

The order of a group $(\mathbf{G}, \cdot)$, denoted as $|\mathbf{G}|$, is the number of elements in the group. So if $\mathbf{G} = \{\mathbf{g}_1, \mathbf{g}_2, \ldots, \mathbf{g}_\mathbf{n}\}$, then $|\mathbf{G}| = \mathbf{n}$.

The order of an element $\mathbf{g} \in \mathbf{G}$, denoted as $|\mathbf{g}|$, is the smallest positive integer $\mathbf{n}$ such that $\mathbf{g}^\mathbf{n} = \mathbf{e}$, where $\mathbf{e}$ is the identity element of the group under the operation~$\cdot$. If no such positive integer $\mathbf{n}$ exists, we say that the order of $\mathbf{g}$ is infinity.

In a cyclic group generated by an element $\mathbf{g}$, the order of $\mathbf{g}$ is equal to the order of the group, i.e., $|\mathbf{g}| = |\mathbf{G}|$. This is because, by definition, we can generate every element in the group by applying the group operation to $\mathbf{g}$ some number of times.

If we have a cyclic group of prime order $\mathbf{q}$, then the set of integers modulo $\mathbf{q}$ forms a field under the operations of addition and multiplication modulo $\mathbf{q}$. This is because a prime order ensures that every non-zero element has a multiplicative inverse. The existence of additive inverses is guaranteed since we're working modulo $\mathbf{q}$. The set of integers modulo $\mathbf{q}$ is often denoted as $\mathbb{Z}_\mathbf{q}$ or $\mathbb{F}_\mathbf{q}$.

Moreover, when we're talking about a cyclic group generated by an element $\mathbf{g}$, the exponents we use to generate the group elements can be thought of as elements of this field. That is, if $\mathbf{G} = \{\mathbf{g}^0, \mathbf{g}^1, \mathbf{g}^2, ..., \mathbf{g}^{\mathbf{q}-1}\}$, then the exponents $0, 1, 2, ..., \mathbf{q}-1$ can be thought of as elements of the field $\mathbb{F}_\mathbf{q}$, since they behave like integers modulo $\mathbf{q}$ under addition and multiplication.

This connection between groups of prime order and fields is fundamental to many areas of mathematics and is particularly important in number theory and cryptography.

In modular arithmetic, an integer $\mathbf{a}$ is a quadratic residue modulo $\mathbf{n}$ if there exists an integer $\mathbf{x}$ such that the congruence $\mathbf{x}^2 \equiv \mathbf{a} \pmod{\mathbf{n}}$ holds.

The set of all quadratic residues modulo $\mathbf{n}$ is usually denoted as $(\mathbb{Z}/\mathbf{n}\mathbb{Z})^2$ or simply as $\mathbf{Q_n}$. In the special case where $\mathbf{n}$ is a prime number $\mathbf{p}$, we denote this set as $(\mathbb{Z}/\mathbf{p}\mathbb{Z})^2$~or~$\mathbf{Q_p}$.

For example, when $\mathbf{p}=5$, the quadratic residues are the numbers that are congruent to the square of some integer modulo $5$. These are $\mathbf{0}$, $\mathbf{1}$, and $\mathbf{4}$, because $0^2 \equiv 0 \pmod{5}$, $1^2 \equiv 1 \pmod{5}$, $2^2 \equiv 4 \pmod{5}$, $3^2 \equiv 4 \pmod{5}$, and $4^2 \equiv 1 \pmod{5}$.

So the set of quadratic residues modulo $5$ is $\mathbf{Q}_5 = \{{0}, {1}, {4}\}$.

\subsection{Discrete logarithm}

The discrete logarithm problem is a mathematical problem in the field of cryptography. Given a group $\boldsymbol{G}$ with generator $\boldsymbol{g}$, and an element $\boldsymbol{h} \in \boldsymbol{G}$, the goal is to find an integer $\boldsymbol{x}$ such that $\boldsymbol{g}^{\boldsymbol{x}} = \boldsymbol{h}$. This is known as the discrete logarithm of $\boldsymbol{h}$ to the base $\boldsymbol{g}$, and is denoted as $\log_{\boldsymbol{g}}(\boldsymbol{h})$.

The discrete logarithm problem is believed to be a computationally hard problem in the modular group, which is a type of group used in cryptography. The modular group, denoted as $(\mathbb{Z}_{\boldsymbol{p}}^{*}, \cdot)$, is the set of integers modulo a prime number $\boldsymbol{p}$ that are relatively prime to $\boldsymbol{p}$, together with the multiplication operation modulo $\boldsymbol{p}$.

The security of many encryption schemes, relies on the assumption that computing the discrete logarithm in the modular group is computationally hard. More specifically, given a prime $\boldsymbol{p}$, a generator $\boldsymbol{g}$ of the group $(\mathbb{Z}_{\boldsymbol{p}}^{*}, \cdot)$, and an element $\boldsymbol{h} \in \mathbb{Z}_{\boldsymbol{p}}^*$, finding the integer $\boldsymbol{x}$ such that $\boldsymbol{g}^{\boldsymbol{x}} \equiv \boldsymbol{h} \pmod{\boldsymbol{p}}$ is believed to be a computationally hard problem.

The hardness of the discrete logarithm problem in the modular group is based on the fact that there is no known efficient algorithm that can solve it for all inputs. The best known algorithm for solving the discrete logarithm problem in the modular group is the number field sieve, which has a sub-exponential time complexity. However, the time complexity of this algorithm is still considered to be too high for practical purposes, especially for large values of $\boldsymbol{p}$. As a result, the discrete logarithm problem is considered to be computationally hard in the modular group, making it a suitable for use in cryptographic applications.

\subsection{Subgroups}

The multiplicative group modulo a prime number $\boldsymbol{p}$, denoted as $\mathbb{Z}_{\boldsymbol{p}}^{*}$, is the set of integers $\{\boldsymbol{1}, \boldsymbol{2}, \ldots, \boldsymbol{p-1}\}$ under multiplication operation modulo $\boldsymbol{p}$. This group has $\boldsymbol{p-1}$ elements, which forms a cyclic group.

For a given generator $\boldsymbol{g}$ in $\mathbb{Z}_{\boldsymbol{p}}^{*}$, it can generate a cyclic subgroup of $\mathbb{Z}_{\boldsymbol{p}}^{*}$ by powers of $\boldsymbol{g}$ modulo $\boldsymbol{p}$. The order of this subgroup is the smallest positive integer $\boldsymbol{k}$ such that $\boldsymbol{g}^{\boldsymbol{k}} \equiv \boldsymbol{1} \ (\text{mod } \boldsymbol{p})$.

Let's denote the order of this subgroup as $\boldsymbol{q}$. If $\boldsymbol{q}$ is also a prime number, then the subgroup is a cyclic subgroup of prime order.

The subgroups of $\mathbb{Z}_{\boldsymbol{p}}^{*}$ can be found by considering all the divisors of the order of the group ($\boldsymbol{p-1}$). For each divisor $\boldsymbol{d}$, the elements $\{\boldsymbol{g}^{\boldsymbol{0}}, \boldsymbol{g}^{(\boldsymbol{p-1})/\boldsymbol{d}}, \boldsymbol{g}^{2(\boldsymbol{p-1})/\boldsymbol{d}}, \ldots, \boldsymbol{g}^{(\boldsymbol{d-1})(\boldsymbol{p-1})/\boldsymbol{d}}\}$ form a subgroup of order $\boldsymbol{d}$. If $\boldsymbol{d}$ is a prime number, then this subgroup is a cyclic subgroup of prime order.

Thus, in the multiplicative group $\mathbb{Z}_{\boldsymbol{p}}^{*}$, the cyclic subgroups of prime order can be generated by the elements that have prime order.

For the Schnorr protocol, we typically use a multiplicative group of a prime modulus $\boldsymbol{p}$ and a subgroup of prime order $\boldsymbol{q}$. The reason is that the security of the Schnorr protocol relies on the hardness of the Discrete Logarithm Problem (DLP) in the subgroup of prime order. If the order of the subgroup is not prime, an attacker could potentially exploit the factorization of the group order to solve the DLP, breaking the protocol's security.

Consider example, a multiplicative group modulo a prime number $p$ is the set $\{{1}, {2}, \ldots, \boldsymbol{p-1}\}$ with multiplication defined modulo $p$. This group is denoted by $\mathbb{Z}_{\boldsymbol{p}}^{*}$. 

Consider the multiplicative group modulo $7$, denoted as $\mathbb{Z}_{\boldsymbol{7}}^{*}$. This set consists of $\{{1}, {2}, {3}, {4}, {5}, {6}\}$. 

In this group, we can find subgroups of prime order. A cyclic subgroup of order $p$ is a subset of the group that can be generated by repeatedly applying the group operation to a single element (known as a generator) and has $p$ elements. The subgroups of $\mathbb{Z}_{\boldsymbol{7}}^{*}$ are:

\begin{itemize}
    \item Trivial subgroup: The subgroup of order $1$ is the trivial subgroup consisting of the identity element $\{{1}\}$.
    \item Subgroups of order $2$: These subgroups consist of the identity and an element of order $2$. In $\mathbb{Z}_{\boldsymbol{7}}^{*}$, the elements of order $2$ are ${6}$ since $6^{2} \mod 7 = 1$. So, the subgroup of order $2$ is $\{{1}, {6}\}$.
    \item Subgroups of order $3$: These subgroups consist of the identity and two other elements. One such subgroup is $\{{1}, {2}, {4}\}$, generated by $2$.
    \item The whole group: This is a subgroup of itself, so $\mathbb{Z}_{\boldsymbol{7}}^{*} = \{{1}, {2}, {3}, {4}, {5}, {6}\}$ is a subgroup of order $6$.
\end{itemize}

Therefore, the subgroups of $\mathbb{Z}_{\boldsymbol{7}}^{*}$ are $\{{1}\}$, $\{{1}, {6}\}$, $\{{1}, {2}, {4}\}$, and $\{{1}, {2}, {3}, {4}, {5}, {6}\}$.

\section{Cryptography}
We used fundamental work of Ivan Damgard \cite{damgaard2010sigma} for definitions of Sigma protocols and Zero Knowledge Proof.

\subsection{NP-relation}
In computational complexity theory, the concept of NP (nondeterministic polynomial time) is a key aspect of classifying problems by their inherent difficulty. An NP problem is one where a solution, when given, can be verified as correct in polynomial time, even if finding the solution might require an exponential amount of time.

A binary relation $\mathbf{R}(\mathbf{x}, \mathbf{y})$ is an NP relation if there is a polynomial-time algorithm that, given $\mathbf{x}$ and $\mathbf{y}$, can check whether $\mathbf{R}(\mathbf{x}, \mathbf{y})$ holds.

This means, if we have an instance of the problem represented by $\mathbf{x}$, and a proposed solution represented by $\mathbf{y}$, the relation $\mathbf{R}(\mathbf{x}, \mathbf{y})$ is true if $\mathbf{y}$ is a valid solution to the problem instance $\mathbf{x}$, and we can verify this fact in polynomial time.

\subsection{Zero Knowledge Proof of Knowledge}
Zero-Knowledge Proofs of Knowledge (ZKPoK) is a cryptographic primitive which allows one party, called the prover, to demonstrate to another party, called the verifier, that they posses a specific piece of information without revealing anything else about this information except the fact of possession \cite{Bellare1992OnDP, Goldwasser1985TheKC}.
The term ``zero-knowledge" comes from the fact that the verifier learns no additional information about the secret beyond the fact that it exists and the prover knows it. 

ZKPoKs are constructed on top of NP problems, which means that ZKPoKs are used to prove that one party knows a $\mathbf{y}$ such that the relation $\mathbf{R}(\mathbf{x}, \mathbf{y})$ holds, without revealing any information about $\mathbf{y}$. This is particularly useful in situations where revealing the solution itself (the $\mathbf{y}$) might be sensitive or detrimental, but proving that a solution exists is necessary.

A Zero-Knowledge Proofs of Knowledge has three main properties:

\begin{enumerate}
    \item \textbf{Completeness:} If the prover's statement is true, they always convince the verifier of its truth.
    \item \textbf{Soundness:} If the prover's statement is false, they cannot convince the verifier of its truth with more than a negligible probability.
    \item \textbf{Zero-knowledge:} The verifier should not learn any new information about the secret other than the fact that the prover knows it.
\end{enumerate}

Zero-knowledge proofs are used in a variety of applications, such as secure authentication systems, privacy-preserving blockchain transactions, secure multi-party computation and electronic election. They can help create secure systems where parties can cooperate without having to reveal sensitive information to each other.

\subsection{Sigma Protocol}
Sigma protocols are a specific type of three-round, interactive Zero-Knowledge Proof (ZKP). The name ``sigma" comes from the shape of the Greek letter sigma $\Sigma$, which visually depicts the structure of the protocol: a first message (commitment) from the prover, followed by a challenge from the verifier, and finally a response from the prover. 

Sigma protocols have a few important properties \cite{damgaard2010sigma}:

\begin{enumerate}
    \item \textbf{Completeness:} If the prover's statement is true, they should be able to convince the verifier of its truth.
    \item \textbf{Special Soundness:} A stronger form of soundness. It means that if a prover can answer two different challenges for the same commitment, then one can efficiently extract the prover's secret.
    \item \textbf{Honest-Verifier Zero-Knowledge:} The protocol satisfies zero-knowledge property only when the verifier follows the protocol honestly. If the verifier is dishonest, they might be able to learn something about the prover's secret.
\end{enumerate}

All sigma protocols are ZKPs (assuming an honest verifier), but not all ZKPs are sigma protocols. Some ZKPs can be non-interactive or have more than three rounds, for example, and therefore would not be considered sigma protocols.

\subsection{Sigma Protocol and Zero Knowledge Proof of Knowledge}

\textit{Special soundness} is a stronger property than \textit{soundness}. In the context of sigma protocols, soundness refers to the inability of a dishonest prover to convince a verifier of a false statement, except with a negligible probability. 

\textit{Special soundness}, on the other hand, means that if a dishonest prover can produce valid responses to two different challenges for the same initial message (commitment), then one can extract the prover's secret. In other words, a dishonest prover cannot cheat without revealing their secret. 

Thus, if a protocol is specially sound, it must be sound. Because a prover who can cheat in a specially sound protocol would reveal their secret, this effectively makes cheating impossible without a substantial risk, which fulfills the basic requirement of soundness.

The \textit{honest-verifier zero-knowledge} property means that a verifier who follows the protocol honestly will not learn anything other than the fact that the prover knows the secret. 

However, this property does not protect against dishonest verifiers who might deviate from the protocol. \textit{Zero-knowledge}, in its full sense, refers to the property that no verifier, honest or dishonest, can learn anything more than the validity of the statement being proved.

While an honest-verifier zero-knowledge protocol doesn't necessarily offer protection against dishonest verifiers, it can often be transformed into a fully zero-knowledge protocol through the use of additional cryptographic techniques. For example, one common technique is the Fiat-Shamir heuristic, which transforms an interactive honest-verifier zero-knowledge protocol into a non-interactive zero-knowledge protocol that is secure against all verifiers.

Thus, while special soundness directly implies soundness, and honest-verifier zero-knowledge protocols can often be transformed into fully zero-knowledge protocols, these stronger properties require additional conditions or transformations.

\subsection{Sigma Protocol Rounds}
In a sigma protocol, there are three main phases: commitment, challenge, and response.

\begin{enumerate}
    \item \textbf{Commitment Phase:} At this phase, the Prover generates a commitment related to a secret value they possess. The commitment is designed so that it doesn't reveal any information about the secret itself. Importantly, once the Prover has made this commitment, the secret cannot be changed - they are ``committed" to it. This prevents the Prover from adjusting their secret to suit the later challenge.
    
    \item \textbf{Challenge Phase:} In the challenge phase, the Verifier generates a random challenge that they send to the Prover. This challenge is used to test whether the Prover actually knows the secret without directly asking for it.
    
    \item \textbf{Response Phase:} Upon receiving the challenge, the Prover calculates a response based on the secret and the challenge. This response is then sent to the Verifier.
    
    \item \textbf{Verification:} The Verifier then checks the response. If the response is consistent with the commitment and the challenge, the Verifier accepts that the Prover knows the secret. If not, the Verifier rejects the claim.
\end{enumerate}

The security of sigma protocols is based on the fact that without knowledge of the secret, it's computationally infeasible for the Prover to generate a valid response to a random challenge, even if they are allowed to choose their own commitment. This allows the Verifier to be confident that the Prover knows the secret if they can respond correctly to the challenge.


\subsection{Illustration of Sigma Protocol}

The Sigma protocol can be illustrated with a simple real-life example - a coin toss game. The game involves two players, the Prover and the Verifier. To play the game, the Verifier tosses a coin, and the Prover is required to guess the outcome. Normally, the winner is determined by whether the Prover's guess is correct or incorrect, and both players would be incentivized to cheat if given the opportunity.

To make the game fair and prevent cheating, the players can use a piece of paper. At the start of the game, the Prover writes down their guess on the paper, which is then folded and hidden from the Verifier's view (i.e., the commitment phase). Then, the Verifier tosses the coin and observes the outcome. Only after the outcome is obtained does the Verifier unfold the paper and read the Prover's guess (i.e., the response phase).

This process ensures that the Prover cannot change their guess after the coin has been tossed, and the Verifier has no knowledge of the guess before the coin was tossed. Therefore, the game becomes fair and the Sigma protocol is satisfied. If both players are rational, they will have no incentive to cheat since the protocol ensures that neither player can gain an advantage.

\subsection{Schnorr protocol} 

The Schnorr protocol is a type of interactive zero-knowledge proof protocol that provides a way for a Prover to demonstrate knowledge of a secret without revealing it to a Verifier. It is widely used in various applications, including digital signatures, secure authentication and electronic elections.

The Schnorr protocol is based on a modular group of a large prime number $\boldsymbol{p}$. All operations in this group are considered group operations, which means that they follow certain algebraic rules. The public settings of the protocol include the prime number $\boldsymbol{p}$, group generators $\boldsymbol{g}$ and $\boldsymbol{h}$, and a secret value $\boldsymbol{w}$ known only to the Prover. The value $\boldsymbol{h}$ is calculated as $\boldsymbol{h} = \boldsymbol{g}^{\boldsymbol{w}}$.

The Schnorr protocol consists of the following phases:
\begin{enumerate}
    \item Commitment phase: The Prover computes a commitment value $\boldsymbol{c} = \boldsymbol{g}^{\boldsymbol{r}}$, where $\boldsymbol{r}$ is a random value chosen by the Prover. The Prover sends this value to the Verifier.
    \item Challenge phase: The Verifier generates a random challenge value $\boldsymbol{e}$ and sends it to the Prover.
    \item Response phase: The Prover computes a response value $\boldsymbol{t} = \boldsymbol{r} + \boldsymbol{e} \cdot \boldsymbol{w}$. The Prover sends this value to the Verifier.
    \item Verification phase: The Verifier checks that $\boldsymbol{g}^{\boldsymbol{t}} = \boldsymbol{c} \cdot \boldsymbol{h}^{\boldsymbol{e}}$. If this equation holds, the Verifier accepts the proof, which means that the Prover knows the secret value $\boldsymbol{w}$. Otherwise, the proof is rejected.
\end{enumerate}

The Schnorr protocol provides several security properties, including completeness, soundness, and zero-knowledge. Completeness means that if the Prover knows the secret value $\boldsymbol{w}$, then the protocol will be successfully completed with high probability. Soundness means that if the Prover does not know the secret value $\boldsymbol{w}$, then it is computationally infeasible for the Prover to convince the Verifier otherwise. Zero-knowledge means that the protocol does not reveal any information about the secret value $\boldsymbol{w}$ to the Verifier, except for the fact that the Prover knows it.

Schnorr protocol is a secure and efficient way for a Prover to demonstrate knowledge of a secret value to a Verifier without revealing the secret itself. It is widely used in various applications where secure authentication and digital signatures are required.

\subsection{Sigma Protocol Combiners}
Sigma protocol combiners are techniques that allow us to combine multiple instances of sigma protocols, resulting in a new protocol that has more complex structure. Combiners allow to obtain sigma protocols with desired structure of the statement being proved without violating the properties of sigma protocol. 

\subsection{Decisional Diffie-Hellman Assumption}
Decisional Diffie-Hellman (DDH) assumption is a computational assumption used in cryptography that underlies the security of many cryptographic protocols. It is related to the Diffie-Hellman problem, which is used in key exchange protocols.

The DDH assumption states that given a tuple of the form $(\mathbf{g}, \mathbf{g}^\mathbf{a}, \mathbf{g}^\mathbf{b}, \mathbf{g}^\mathbf{c})$, where $\mathbf{g}$ is a generator of a group $\mathbf{G}$, and $\mathbf{a}$, $\mathbf{b}$, $\mathbf{c}$ are randomly chosen from the group's order, it is computationally infeasible to decide whether $\mathbf{c}$ equals $\mathbf{a} \cdot \mathbf{b}$ or not, i.e., whether the fourth element of the tuple is $\mathbf{g}^{\mathbf{a} \cdot \mathbf{b}}$ or a random group element.

The tuple $(\mathbf{g}, \mathbf{g}^\mathbf{a}, \mathbf{g}^\mathbf{b}, \mathbf{g}^\mathbf{c})$ is often referred to as a Decisional Diffie-Hellman tuple. If $\mathbf{c} = \mathbf{a} \cdot \mathbf{b}$, it is said to be a Diffie-Hellman tuple, otherwise, it's a random tuple. The DDH assumption says that these two cases are computationally indistinguishable from each other.

Please note that the DDH assumption does not hold in all groups. For example, in the multiplicative group of integers modulo a prime p, the problem is easy. Therefore, when using DDH in cryptography, it's important to choose a suitable group.


\subsection{ElGamal encryption scheme}
The ElGamal encryption scheme is a public-key cryptosystem based on the difficulty of computing discrete logarithms. It was proposed by Taher ElGamal in 1985 \cite{ElGamal:1985} and is widely used in various applications, including email, online messaging, secure data transmission and electronic elections.

The ElGamal encryption scheme involves two main components: a public key and a private key. The public key is known to everyone, while the private key is kept secret by the owner. The encryption and decryption processes involve both keys, as described below:

\textbf{Key generation:}

\begin{enumerate}
    \item Select a large prime $\boldsymbol{p}$ and a generator $\boldsymbol{g}$ of the multiplicative group modulo~$\boldsymbol{p}$.
    \item Choose a random integer $\boldsymbol{x}$ from the range $1 \leq \boldsymbol{x} \leq \boldsymbol{p}-1$.
    \item Calculate the public key $\boldsymbol{y} = \boldsymbol{g} ^ {\boldsymbol{x}} \mod \boldsymbol{p}$.
    \item The public key is $(\boldsymbol{p}, \boldsymbol{g}, \boldsymbol{y})$ and the private key is $\boldsymbol{x}$.
\end{enumerate}

\textbf{Encryption:}

\begin{enumerate}
    \item Choose a random integer $\boldsymbol{k}$ from the range $1 \leq {\boldsymbol{k}} \leq {\boldsymbol{p}}-1$.
    \item Compute $\boldsymbol{C}_1 = {\boldsymbol{g}}^{\boldsymbol{k}} \mod {\boldsymbol{p}}$ and $\boldsymbol{C}_2 = {\boldsymbol{m}} \cdot {\boldsymbol{y}}^{\boldsymbol{k}} \mod {\boldsymbol{p}}$, where ${\boldsymbol{m}}$ is the message to be encrypted.
    \item The ciphertext is $({\boldsymbol{C}}_1, {\boldsymbol{C}}_2)$.
\end{enumerate}

\textbf{Decryption:}

\begin{enumerate}
    \item Calculate ${\boldsymbol{D}} = {\boldsymbol{C}}_1^{\boldsymbol{x}} \mod {\boldsymbol{p}}$.
    \item Compute ${\boldsymbol{m}} = {\boldsymbol{C}}_2 \cdot {\boldsymbol{D}}^{-1} \mod {\boldsymbol{p}}$, where ${\boldsymbol{D}}^{-1}$ is the modular multiplicative inverse of ${\boldsymbol{D}}$ modulo ${\boldsymbol{p}}$.
\end{enumerate}

The security of the ElGamal encryption scheme is based on the discrete logarithm problem, which is considered a hard problem in number theory. The discrete logarithm problem states that given a prime number $\boldsymbol{p}$, a primitive root $\boldsymbol{g}$ modulo $\boldsymbol{p}$, and a number $\boldsymbol{y}$, it is computationally infeasible to find an integer $\boldsymbol{x}$ such that $\boldsymbol{y} = \boldsymbol{g}^{\boldsymbol{x}} \mod \boldsymbol{p}$, especially if $\boldsymbol{p}$ and $\boldsymbol{g}$ are large enough.

The Decisional Diffie-Hellman Assumption (DDH) is a cryptographic assumption made in the field of cryptography. It is related to the Diffie-Hellman problem and is used in the security proof of ElGamal encryption. In particular, the DDH assumption states that for a group generator $\boldsymbol{g}$, given $\boldsymbol{g^a}$, $\boldsymbol{g^b}$ and $\boldsymbol{g^c}$ for some random $\boldsymbol{a}$, $\boldsymbol{b}$



\subsection{Exponential ElGamal encryption scheme}
The Exponential ElGamal encryption scheme is a variant of the original ElGamal encryption scheme that uses a different method for encrypting messages. It was proposed by Victor Shoup in 1997 \cite{Shoup:1997} and is also based on the difficulty of computing discrete logarithms.

The Exponential ElGamal encryption scheme involves two main components: a public key and a private key. The public key is known to everyone, while the private key is kept secret by the owner. The encryption and decryption processes involve both keys, as described below:

\textbf{Key generation:}

\begin{enumerate}
    \item Select a large prime $\boldsymbol{p}$ and a generator $\boldsymbol{g}$ of the multiplicative group modulo $\boldsymbol{p}$.
    \item Choose a random integer $\boldsymbol{x}$ from the range $1 \leq \boldsymbol{x} \leq \boldsymbol{p}-1$.
    \item Calculate the public key $\boldsymbol{y} = \boldsymbol{g} ^ {\boldsymbol{x}} \mod \boldsymbol{p}$.
    \item The public key is $(\boldsymbol{p}, \boldsymbol{g}, \boldsymbol{y})$ and the private key is $\boldsymbol{x}$.
\end{enumerate}

\textbf{Encryption:}

\begin{enumerate}
    \item Choose a random integer $\boldsymbol{k}$ from the range $1 \leq {\boldsymbol{k}} \leq {\boldsymbol{p}}-1$.
    \item Compute $\boldsymbol{C}_1 = {\boldsymbol{g}}^{\boldsymbol{k}} \mod {\boldsymbol{p}}$ and $\boldsymbol{C}_2 = {{\boldsymbol{g}}^{\boldsymbol{m}}} \cdot {\boldsymbol{y}}^{\boldsymbol{k}} \mod {\boldsymbol{p}}$, where ${\boldsymbol{m}}$ is the message to be encrypted.
    \item The ciphertext is $({\boldsymbol{C}}_1, {\boldsymbol{C}}_2)$.
\end{enumerate}

\textbf{Decryption:}

\begin{enumerate}
    \item Calculate ${\boldsymbol{D}} = {\boldsymbol{C}}_1^{\boldsymbol{x}} \mod {\boldsymbol{p}}$.
    \item Compute $ {\boldsymbol{m}} =\log_{\boldsymbol{g}}(\boldsymbol{{\boldsymbol{C}}_2 \cdot {\boldsymbol{D}}^{-1} \mod {\boldsymbol{p}}})$, where ${\boldsymbol{D}}^{-1}$ is the modular multiplicative inverse of ${\boldsymbol{D}}$ modulo ${\boldsymbol{p}}$.
\end{enumerate}

The security of the Exponential ElGamal encryption scheme is based on the computational difficulty of computing discrete logarithms in a multiplicative group modulo a large prime. Specifically, given $\boldsymbol{p}, \boldsymbol{g}$ and $\boldsymbol{y}$ it is difficult to find ${\boldsymbol{x}}$ such that ${\boldsymbol{y}} = {\boldsymbol{g}}^{\boldsymbol{x}} \mod {\boldsymbol{p}}$, especially if ${\boldsymbol{p}}$ is large and chosen properly.

Exponential ElGamal encryption scheme is a variant of the original ElGamal encryption scheme that provides secure encryption and decryption of messages based on the difficulty of computing discrete logarithms. It is widely used in various applications that require secure and efficient data transmission over insecure channels.


\subsection{Chaum-Pedersen protocol}

In the context of electronic voting, this protocol is frequently used to prove that the vote encryption was done correctly, or that an encrypted vote is well-formed. This is important because it allows the verification of the correctness of an encrypted vote without revealing the vote itself, preserving the voter's privacy.

The Chaum-Pedersen protocol works by operating on pairs of elements $(\mathbf{g},\mathbf{h})$ in a cyclic group $\mathbf{G}$, where $\mathbf{g}$ is a generator and $\mathbf{h}$ is an element of the group. The prover wants to convince the verifier that they know a secret value $\mathbf{x}$ such that $\mathbf{h} = \mathbf{g}^{\mathbf{x}}$, without revealing $\mathbf{x}$.

The prover picks a random value $\mathbf{r}$ from the same set as $\mathbf{x}$, computes $\mathbf{t} = \mathbf{g}^{\mathbf{r}}$ and sends $\mathbf{t}$ to the verifier.
The verifier sends back a challenge value $\mathbf{c}$, chosen randomly from a large enough set.
The prover computes $\mathbf{z} = \mathbf{r} + \mathbf{c}\cdot\mathbf{x}$ and sends $\mathbf{z}$ to the verifier.
The verifier checks that $\mathbf{g}^{\mathbf{z}}$ equals $\mathbf{t}\cdot\mathbf{h}^{\mathbf{c}}$. If this is the case, the verifier accepts the proof. If not, the verifier rejects the proof.

This protocol ensures that unless the prover knows the secret value $\mathbf{x}$, they cannot create values $\mathbf{t}$ and $\mathbf{z}$ that make the verification equation hold for a randomly chosen challenge $\mathbf{c}$. This allows a voter to convince the election authority that their encrypted vote is well-formed, without revealing the vote itself or any information that could help deduce it.


\section{Electronic Elections}

\subsection{Helios Voting}
The Helios Voting is an open-source voting platform that offers secure and anonymous electronic voting. It was developed by Ben Adida \cite{Adida2008HeliosWO} and is designed to be transparent, verifiable, and easy to use. The source code and specification are available online.

Helios has been subjected to extensive scientific research, with numerous instances of critical errors having been discovered \cite{Heiderich2011TheBT, ChangFong2016TheCS, Cortier2011AttackingAF, Acemyan2015FromET, Bernhard2012HowNT, Bernhard2011AdaptingHF} and fixed as well as suggested improvement implemented. However, Because of these changes, Helios is one of the most evolving electronic election platform. In addition, the International Association for Cryptologic Research (IACR) \cite{iacr} uses Helios Voting for its director elections, providing us with confidence in its security and reliability.

The Helios system uses a mix of cryptographic protocols, including homomorphic encryption, zero-knowledge proofs, and threshold cryptography, to achieve its security goals. Homomorphic encryption allows tallying to be performed on encrypted data without decrypting it Additionally, Helios rejects invalid voter choices. Threshold cryptography allows for the distribution of secret keys among multiple parties to prevent any single party from accessing the secret. However, it is important to note that all the above properties are guaranteed only if cryptography is correctly implemented, which currently remains not proven.

Helios provides election audit functionality for users to verify the election results as well as published evidence data for election audit. This verification process requires complex computations that cannot be checked manually. However, it's important to note that the election implementation and verification tool are not formally verified, which means they may contain errors. 

Some of the key features of the Helios system include:

\begin{itemize}
    \item Voter privacy: Each voter can cast their ballot anonymously without revealing their identity or vote choice to anyone else.
    \item End-to-end verifiability: The Helios system provides a mechanism for voters to verify that their vote was recorded correctly and counted as part of the final tally.
    \item Auditing: The system generates a cryptographic proof that allows anyone to verify the integrity of the election results, even if they do not trust the election administrators.
    \item Trustworthiness: The system is designed to be transparent and open-source, allowing anyone to inspect the code and verify that the system is functioning as intended.
\end{itemize}

One potential downside of the Helios system is that it requires a high degree of technical expertise to set up and run securely. Additionally, similar to all online voting systems, it is vulnerable to attacks from hackers or other malicious actors. For these reasons, the use of Helios or any other online voting system should be carefully considered and evaluated in the context of the specific election or voting scenario.


\subsection{Helios election protocol} 
Helios voting is using Exponential version of ElGamal  encryption and a non-interactive version of Chaum-Pedersen sigma protocol, the following explanation is based on Helios Voting specification\cite{Adida2008HeliosWO, Helios}. We visited the components earlier, here we provide an explanation of how Helios election protocol works. This Sequence of steps is required for each voter's choice \\

\begin{enumerate}
\item \textbf{Public Setup:}

    \begin{itemize}
        \item The parameters $p$ and $q$ are large prime numbers such that $q$ is a divisor of $p-1$. This creates a cyclic group of order $q$ with $p$ as the modulus.
        \item The value $g$ is a generator of the cyclic group, meaning that every element of the group can be obtained by raising $g$ to some integer power. A common method for finding a generator $g$ is to start with a random number and keep incrementing it until a generator is found.
        \item The parameters $p$, $q$, and $g$ are made public so that they can be used for the encryption and decryption processes. In particular, $g$ is used in the generation of public and secret keys, as well as in the encryption of votes.
    \end{itemize}


    \item \textbf{Key Generation:}
    \begin{itemize}
        \item Each trustee independently generates a pair of keys - a public key and a secret key. They do this by selecting a random number from a large enough set as their secret key. The public key is then generated by raising a generator $g$ of a cyclic group $G$ to the power of their secret key.
        \item For the case of two trustees (there can be many), we denote the secret key of the first trustee as $\textbf{x}_1$ and their public key as $\textbf{y}_1$. Similarly, we denote the secret key of the second trustee as $\textbf{x}_2$ and their public key as $\textbf{y}_2$.
        \item Each trustee keeps their secret key private and shares their public key with the other trustee and the public. The overall public key $\textbf{y}$ for the election is computed by multiplying the individual public keys of the trustees in the group $G$ (i.e., $\textbf{y} = \textbf{y}_1 \cdot \textbf{y}_2$). The trustees will need to use their respective secret keys ($\textbf{x}_1$ and $\textbf{x}_2$) to jointly decrypt the final tally.
    \end{itemize}

    
    \item \textbf{Ballot Preparation:}
    \begin{itemize}
        \item The voter selects their candidate of choice , represented by an integer , and this is denoted as \( \mathbf{m} \).
        \item This choice is then encrypted using exponential ElGamal encryption, resulting in \( \mathbf{\alpha} = \mathbf{g}^{\mathbf{r}} \) and \( \mathbf{\beta} = \mathbf{y}^{\mathbf{r}} * \mathbf{g}^{\mathbf{m}} \), where \( \mathbf{r} \) is a randomly chosen number by the voter, \( \mathbf{g} \) is the generator of the cyclic group, and \( \mathbf{y} \) is the public key.


        \item Using Chaum-Pedersen Protocol the voter generates a zero-knowledge proof to show that the vote is correctly encrypted, without revealing the vote itself. This involves the following steps:
        \begin{itemize}
            \item The voter generates a random value $\textbf{w}$ and computes \\
            $\textbf{A} = \textbf{g}^{\textbf{w}}$ and $\textbf{B} = \boldsymbol{y}^{\textbf{w}}$.
            \item The voter computes a hash $\textbf{e} = \text{Hash}(\boldsymbol{\alpha}, \boldsymbol{\beta}, \textbf{A}, \textbf{B})$ of the values, which serves as a challenge in the protocol. The function ``Hash" is a cryptographic hash function that maps data of arbitrary size to a fixed-size bit string.
            \item The voter computes $\textbf{t} = \textbf{w} + \textbf{r} * \textbf{e}$ and sends the proof $(\textbf{A}, \textbf{B}, \textbf{e}, \textbf{t})$ alongside the encrypted vote $(\boldsymbol{\alpha}, \boldsymbol{\beta})$.
        \end{itemize}
 
    \end{itemize}


    
    \item \textbf{Tallying:}
        \begin{itemize}
        \item Once the voting phase is over, the election server starts the tallying phase. The server performs a homomorphic tally by computing the product of all the \( \mathbf{\alpha} \) and \( \mathbf{\beta} \) values from the ballots, resulting in \( \mathbf{\alpha_{tally}} = \prod_{i=1}^{n} \mathbf{\alpha_i} \) and\\
        \( \mathbf{\beta_{tally}} = \prod_{i=1}^{n} \mathbf{\beta_i} \), where \( n \) is the total number of ballots.
        \item This tally represents an encrypted version of the total votes for each candidate.
        \item Note that due to the properties of the exponential ElGamal encryption scheme, this tallying process does not reveal any individual votes, preserving the privacy of the voters.
    \end{itemize}


\item \textbf{Decryption:}
    \begin{itemize}
    \item The decryption process is performed by the trustees. Each trustee computes the decryption factor and decryption proof for the encrypted tally. The decryption factor \(d_i\) for trustee \(i\) is calculated as \(d_i = \alpha_{tally}^{x_i}\), where \(x_i\) is the private key of trustee \(i\). 
    \item Each trustee also computes a zero-knowledge proof, referred to as the decryption proof, that they correctly computed their decryption factor. This proof uses the Chaum-Pedersen protocol and is a tuple \((t_i, c_i, z_i)\), where \(t_i = g^{w_i}\), \(c_i = \text{Hash}(g, \alpha_{tally}, t_i, d_i)\), and \(z_i = w_i + c_i \times x_i\), with \(w_i\) being a random number. The decryption proof is then sent to the election server along with the decryption factor.
    \item The server checks each trustee's decryption proof. If all proofs are valid, the server calculates the final decryption factor \(D = \prod_{i=1}^{n} d_i\), where \(n\) is the number of trustees. 
    \item The server then computes the election result by calculating \(m = \log_g \left(\frac{\beta_{tally}}{D}\right)\), which reveals the total number of votes for each candidate. The logarithm here is the discrete logarithm in the base \(g\), which is computationally hard to calculate but feasible given the decryption factor \(D\).
    \item Note: Here, the division operation \(\frac{\beta_{tally}}{D}\) is the group inverse operation. In a group, for every element, there exists an inverse element such that their product is the identity element of the group. Therefore, \(\frac{\beta_{tally}}{D}\) is equivalent to multiplying \(\beta_{tally}\) with the group inverse of \(D\).
    \end{itemize}

\end{enumerate}

Finally, the Helios server publishes the final tally and a zero-knowledge proof transcript for public evidence that demonstrates the integrity of the tally without revealing any information about the individual votes. Voters can then verify that their vote was counted correctly by comparing the published tally with the encrypted ballot that they submitted.

Helios election protocol is a cryptographic protocol that enables secure and anonymous electronic voting using a combination of sigma protocols, homomorphic encryption, and other cryptographic techniques. The protocol is designed to be verifiable, transparent, and resistant to various types of attacks, and is commonly used in cryptographic applications such as electronic voting.


\subsection{IACR 2022 Director Election with Helios} 
This section do not need to be here as schnorr is just a model.
IACR is a International Association for Criptographical Research \cite{iacr}. This organisation is using Helios election for their elections. We are using their latest (2022) director election as a subject for our work.

The election of IACR director in 2022 has 6 question (copy from scope section)
Helios election protocol involves the use of sigma protocols to enable voters to cast their votes anonymously and securely. There are 6 candidates, and each voter can vote for or against each of the 12 questions using a binary 0/1 vote. 

The protocol involves a global setup phase where a prime $p$ and $q$ are chosen, and an election private key $x$ is computed as the sum of individual private keys $x_i$. The public key $y$ is computed as $g^x$, where $g$ is a generator. There are 3 trustees. Each trustee generates their own private key $x_i$ and computes their public key $y_i$. A Schnorr proof is used to prove knowledge of $x_i$. 

In the next step, the voter receives the public key $y = g^x$ and picks their votes for the candidates using plaintext $m \in \{0,1\}$. The voter then generates random coins $r$ and $w$, and computes ciphertext $cph$ as a commitment to their vote using a disjunctive combiner. The voter sends the commitment to the Helios server, who responds with a proof of equality using ElGamal decryption. The verifier then checks the validity of the proof, and that the vote is valid and has been correctly applied.

Finally, the Helios server receives the ciphertext from the trustees and computes the final result of the election using the public keys $y_i$ and the values of $m$ from the ciphertexts. The server computes the sum of individual private keys $x_i$ to obtain the final private key $x$, and computes the public key $y$ as $g^x$. The server then computes the final result of the election by solving the discrete logarithm problem to obtain the actual sum of the votes. \\


\subsection{Software Independence} 
``Software Independence" is a term that was introduced by Ronald L. Rivest, \cite{Rivest2008OnTN} a renowned computer scientist and cryptographer at MIT, and John P. Wack, a computer scientist at NIST, in their paper titled ``On the Notion of Software Independence in Voting Systems". 

The term ``software independence" is used to refer to a characteristic of a voting system where an undetectable change or error in the system's software cannot result in an undetectable alteration or error in the outcome of an election. In simpler terms, a voting system is considered software-independent if even a flaw in the software cannot lead to an undetected change in the election results. 

This concept is vital to maintain the integrity of the voting process. In the context of voting systems, software independence is desirable because it guarantees that, despite potential bugs or vulnerabilities in the voting software, or even in cases where the software is compromised by malicious attacks, the correct election results can still be determined reliably. 

In their paper, the authors suggest several methods to achieve software independence. These include Voter Verified Paper Ballots (VVPB) and End-to-End (E2E) cryptographic voting systems. VVPB systems provide voters the ability to verify that their vote is accurately recorded on a paper ballot, which can then be used for a reliable recount, if necessary. E2E cryptographic voting systems, on the other hand, leverage complex cryptographic techniques to ensure that votes are cast as intended, recorded as cast, and counted as recorded, all while preserving voter privacy.

However, it is important to note that software independence does not imply that the software's significance is diminished or that errors in the software are tolerable. The software should be as accurate and secure as possible. But software independence provides an added layer of assurance, ensuring that even if something does go wrong with the software, the election results can still be trusted.


\subsection{Election verification} 

In the context of electronic voting, there are several important properties for an electronic voting system. Here we give a short overview of most interesting for us properties to describe better the position of our research target.

\begin{enumerate}
\item \textbf{Privacy}: In any voting context, privacy is paramount. It's important that a voter's choice remains anonymous to prevent any possible repercussions due to their political leanings or voting preferences. This is often referred to as ``ballot secrecy". In an electronic voting system, privacy also extends to ensuring that voters' identities are protected and that their personal information is not leaked or misused \cite{cranor2005security}.

\item \textbf{Security}: The system should resist various types of attacks, such as attempts to disrupt the voting process, attempts to change votes, or attempts to break voters' privacy \cite{cranor2005security}.

\item \textbf{Integrity}: This relates to the accuracy and reliability of the voting process. The system must ensure that every vote is counted accurately, that votes cannot be changed after they have been cast, and that no votes are added or removed fraudulently \cite{ryan2009modelling}.

\item \textbf{Verifiability}: There are two types of verifiability to consider - individual and universal. Individual verifiability allows a voter to verify that their own vote was correctly recorded and included in the final tally. Universal verifiability allows anyone to check that the election outcome correctly reflects the recorded votes \cite{ryan2009modelling}. Helios Voting provides public evidence data to verify election integrity.
\end{enumerate}

These properties can be challenging to achieve in full, and there can be trade-offs between them. For example, improving verifiability or auditability might involve keeping more information about votes, which could potentially threaten privacy if not done

In the current paper we are interested in verifying integrity of election. However, we have to take privacy into account as well. Integrity and Privacy are often balanced against each other. Increasing privacy (for example, by adding more layers of encryption) can make it more difficult to audit the votes and ensure integrity. Conversely, increasing the ability to audit votes (for example, by adding more detailed logging) can potentially decrease privacy if not done carefully.

Integrity can be verified using provided public evidence data.  Integrity checks include 3 checks:
cast-as-intended, collected-as-cast and tallied-as-collected.

These properties form a fundamental framework for understanding the integrity of electronic voting systems. Each property addresses a different aspect of the voting process to ensure that the final election results accurately represent the choices of the electorate.

\begin{enumerate}
\item \textbf{Cast as intended}: This property focuses on ensuring that a voter's choice is accurately recorded by the electronic voting system. When a voter casts their vote, the system should capture their selection exactly as they intended it. Techniques similar to end-to-end (E2E) verifiable systems allow voters to verify that their votes have been recorded as intended without compromising their privacy. 
Cast as intended property is not completely universally verifiable as it requires knowledge of the actual intended vote. The value of intended vote is private and only available to the voter themselves but not to other people. However, encryption proof of the vote can be verified universally .

\item \textbf{Collected as cast}: This property ensures that the votes that are collected by the election system are the same votes as have been cast. Additionally, individual verifiability can help in achieving this property, as it allows voters to verify that their votes have been collected correctly. This property is not universally verified as cast votes in Helios are encrypted and public ecvidence data contains a record of the encrypted votes. Only Voters can check that there are the same encrypted votes have got recorded for further tallying. Universally verifiable is validity of encryoption of the collected ballots .

\item \textbf{Tallied as collected}: The focus of this property is to check if the votes that were counted are the same votes as have been collected. This property is universally verifiabile, which allows anyone to confirm that the final results are consistent with the collected votes. In helios tallying is homomorphic, which means that encrypted votes are being tallied and result is decrypted in the end.
\end{enumerate}

Together, these properties help to guarantee the integrity of electronic voting systems by addressing different stages of the voting process. They are essential to establishing trust in the electoral process and ensuring that the results accurately reflect the will of the voters.

In order to guarantee election integrity we do not always need to prove that implementation of election code is correct, thanks to software independence we need much less.
Concept of ``software independence" in the context of electronic voting systems was proposed by Ron Rivest and John Wack \cite{Rivest2008OnTN}. In their work, Rivest and Wack define a voting system as software-independent if an undetected change or error in its software cannot cause an undetectable change or error in an election outcome. In other words, it should be possible to check the integrity of an election result without relying on the trustworthiness of the voting software.

This principle is designed to protect the integrity of elections, especially when using electronic voting systems. By requiring a physical, auditable trail (similar to a paper trail) that can be checked independently of the software, the principle aims to ensure that errors or tampering with the voting software cannot silently change the outcome of an election.

Therefore, it suffice to verify the generated transcript to verify elections integrity.


    \subsection{Meaning of Correctness} 
    
    The terms ``correct" and ``correctness" are frequently used in our work, and their meanings may vary depending on the context. Generally, correctness is determined by either purpose or definition. In the case of a sigma protocol, we have a formal definition that is introduced by \cite{Cramer1997ModularDO} and formalized by \cite{Barthe2009FormalCO, Smyth2015ElectionVC}. Therefore, a correct sigma protocol is one that satisfies its definition.
    
    When dealing with the correctness of an election, we are often interested in specific properties. Therefore, for the purposes of this work, we limit the definition of the word ``correct" for an election to only these specific properties previously described - universally verified subset of integrity properties. For an election verifier to be considered correct within the present work, it must comply with its purpose and guarantee those three election properties. Namely, a correct verifier implies that if the verifier accepts an election transcript, then the election is correct. Note that the converse is not true; if the verifier does not accept it, it does not necessarily mean that the election is fraudulent.
    
    In this work, we use the term ``verify" election in reference to ensuring the three election properties mentioned earlier. We also frequently state that the CakeML compiler is ``correct" or ``verified," which means that the produced executable program behaves precisely as it is written in its code and this fact is guaranteed.
    
    We also appreciate the fact that HOL4 is correct, which means that the HOL environment does not accept false proofs. Therefore, if a fact is proven within the HOL environment, it is guaranteed to be true.




