\chapter{Related Work}\label{chap:relatedWork}
\section{Related Work Overview} 
There are various angles from which to address the issue of ensuring the correctness of elections, and extensive efforts are being made to improve the situation on multiple dimensions and scales. In this work, we focus on the efforts that contribute to ensuring election correctness and identify four main areas of work in this regard. We will discuss these areas in descending order of breadth.
\begin{itemize}
    \item Firstly, there is the implementation of sigma protocols in general. These protocols are commonly used in electronic elections, but their application extends beyond this context, making this a broader area of work.
    \item Secondly, a more specific area of focus is the design of election protocols and their verifiability. This involves mostly theoretical designing of protocols to meet specific requirements for election implementation.
    \item Thirdly, an even narrower field of work involves identifying and exposing errors and vulnerabilities in electronic elections. This can involve analyzing election protocols or software code for errors.
    \item Finally, the most specific area of work is the verification of deployed electronic election. This involves verifying that the particular conducted election has been done correctly, in accordance to requirements specified in the election protocol and that the errors did not occur in this election instance.
\end{itemize}

We discuss notable contributions in each of these areas, understand their value, relevance, and interconnections of these areas of work as well as position our own work in relation to them.


\section{General Sigma Protocol Correctness}
Sigma protocol ia a cryptographic primitives that have applications beyond elections. Several publications have contributed to the correctness of general sigma protocol implementation, thereby aiding in ensuring the correctness of electronic elections. This work began with seminal contribution of Barth et al.\cite{Barthe2010AMF}, who formalized sigma protocols using the Coq theorem prover. They formalised the fundamental definition of sigma protocol, and its properties: Completeness, Special Soundness, and Honest Verifier Zero-knowledge, introduced by Cramer et al. \cite{Cramer1997ModularDO}, providing formal machine-checked proofs. To prove the Honest Verifier Zero-knowledge property, they used a stronger property called ``special Honest Verifier Zero-knowledge" and demonstrated that it implies the classic Honest Verifier Zero-knowledge. Additionally, they provided formalization for Conjunctive and Disjunctive combiners, which are used for constructions of more useful protocols, and proved the required properties about the combiners. As well as for some instances of sigma protocols such as Schnorr and Fiat-Shamir sigma protocol. This work offers formal machine-checked proof of sigma protocols, bridging the gap between theoretical concepts and proven implementation. However, despite its theoretical significance, it does not yield any proven executable program. While Barth's use of Coq is commendable, it lacks foresight, as the ultimate goal of the code is to be compiled and run, however, Coq's extraction mechanism is not formally verified correct. Thus the compilation does not transmit proven correctness to the operation of the program. It would be more justified to use HOL theorem prover, because proven correct code in HOL theorem prover can be compiled into a guaranteed correct executable using the verified CakeML compiler \cite{Tan2016ANV, Kumar2015ProofgroundedBO}.

Building on work of Barth et al.\cite{Barthe2010AMF}, Almeida et al. \cite{Almeida2010ACC} developed a toolkit that generates an implementation of sigma protocol on demand along with the correctness proof. This toolkit can produce correctly implemented sigma protocol code in C language and a correctness certificate, given a required proof description. This approach is more efficient as it absolves users from any errors in the sigma protocol and delegates the complexity of sigma protocols implementation to professional cryptographers. Unlike Barth, Almeida used the Isabelle/HOL theorem prover to develop definitions and theorems, which is a better approach because from Isabelle/HOL environment executable program can be compiled by the verified compiler \cite{Hupel2018AVC}. However, the generated correct code that Almeida's system produces is in C language, which does not formally guarantee correct execution of the compiled program. Therefore, it is the developer's responsibility to compile the code and ensure that the executable is operating correctly.

In a subsequent work, Almeida et al. \cite{Almeida2012FullPC} improved the sigma protocol compiler further. The updated compiler can now return a correct sigma protocol in either C or Java implementation. They expanded the functionality and optimized the implementation, but now proofs are implemented in the Coq theorem prover. While this work aims to delegate responsibility from the software developer to the cryptographer, it does not fully realize this goal. The compilation of Java or C code still leaves a correctness verification gap and retains partial responsibility on the developer. Compilers commonly have errors and Yang et al. \cite{Yang2011FindingAU} have demonstrated instances of compiler errors being exposed. While this level of guarantee might suffice for certain systems, it falls short for electronic elections.

Haines et al.\cite{Haines2019VerifiedVF} criticize Almeida's sigma protocol toolkit for being not applicable for development of election protocols because they target a more general problem of sigma protocols correctness while excessively specialised to narrow set of ZKPoK. Their toolkit is only suitable for a few special cases of electronic elections protocol. However, I believe that the main reason it is not suitable for developing of an election verifier is more fundamental: regardless of the functionality (specific or generic) and available range of sigma protocols (wide or narrow), Almeida's toolkit cannot conceptually guarantee the correctness of an executable, which is required for election verification if we want to rely on   ``Software Independence" concept \cite{Rivest2008OnTN}. Nevertheless, Almeida's work represents a significant advancement in the development of correct sigma protocols.

\section{Election Verifiability}
This line of research is closer related to our current project than the previous one, as it aims to enhance the theoretical definition of electronic election properties and contributes to the verifiability of elections. Specifically, these works provide a potential target for election verifiers, such as the one we are developing techniques for.

Haines et al. \cite{Haines2019VerifiableHT}. contributed to the field of electronic voting by working on the election protocol for the Schulze Voting Scheme. This scheme is a preferential voting system that determines the outcome of an election by calculating a ``path strength" between each pair of candidates. The path strength represents the strength of the majority preference between two candidates, and the method considers all possible paths between each pair of candidates to choose the strongest path as the basis for comparison. This method satisfies a number of desirable voting method criteria making it robust. However, the Schulze method may fail the ballot privacy property when the number of candidates is high, which can lead to coercion and bribery.

In electronic voting, coercion refers to situations where voters are unduly influenced or forced to vote a certain way by a third party. This can involve threats, bribery, or intimidation. A robust electronic voting system should be coercion-resistant, ensuring that even under coercion, the secrecy of a voter's choice is maintained, preventing the coercer from verifying the actual vote.

The proposed election protocol designed to preserve ballot privacy while keep tallying universally verifiable. The team used Zero Knowledge Proof and homomorphic tallying to provide the above properties. The protocol involves two phases: homomorphic calculation of the encrypted matrix and determination of winners based on the decrypted matrix. The calculations result an evidence that ensures the correctness of the matrix and decide the winners. Ballots are represented as matrices, where +1 represents preference for one candidate over another, -1 represents preference for the other candidate over the first, and 0 represents equal preference. Each ballot is verified to be valid, and shuffled by a secret permutation, permutations of ballots are used to provide evidence of the validity of encrypted ballots. Zero-knowledge proofs are used to provide evidence of the correctness of shuffles and correctness of decryption. The certificate includes evidence of correct counting, the updated margin matrix, and winners with evidence to support the claim. This work develops an election protocol that provides universally verifiable tallying and preserves ballot privacy. 

The authors recognized some limitations in their work, such as the use of unverified cryptographic primitive components from an external library and the extraction of code for compilation using an unverified Coq extractor module. Despite these limitations, we appreciate this work as a theoretical advancement of an election protocol with a universally verifiable tallying property, which could serve as a target for a verifier akin to ours. The fact that the tools are unverified doesn't pose an issue for us, as it aligns with our approach. We can refer to the ``Software Independence" concept \cite{Rivest2008OnTN} and employ our proven correct verifier to ensure the correctness of such an election.

The subsequent contribution to the development of the election protocol pertains to improvements applied to the Helios voting system. This work is of interest to us because the properties of the election protocol provide a target for external verification, which is the primary focus of our study. Furthermore, we have utilized the Helios voting system \cite{Adida2008HeliosWO} as our test subject to examine and demonstrate the functionality of our developed technique. Therefore, we are particularly interested in the properties of the Helios election protocol and its enhancements.

Kulyk et al.\cite{Kulyk2015ExtendingHT}  proposed enhancements to the Helios \cite{Adida2008HeliosWO} system by amending such properties as ``participation privacy" and ``eligibility verifiability". Participation privacy property enables an election auditor to confirm that information about voter participation was kept confidential. Eligibility verifiability lets an auditor to confirm that the tally counted only the ballots from the voters who are eligible. However, maintaining these properties simultaneously presents a challenge. Building on this work, Bernhard et al.\cite{Bernhard2017SecurityPF} formally defined and proved these additional properties, enabling them to coexist. Verifying these properties for a real election necessitates the development of verification tools, which should themselves be verified to ensure reliability. These verifiers could be a potential area of our research or similar work, and our developed elementary components could potentially be used to construct a verifier for these properties. However, this is not the focus of our current proposal as we aim to verify different properties.

\section{Challenging Elections}
Electronic elections can be prone to a variety of errors, which is why election verification is so important. The discovery of these errors highlights the need for stronger election guarantees, which can be achieved through verification. Switzerland is a strong democracy and has a long history of electronic election adoption; however, even in Swiss government elections, multiple errors have been discovered. In the following papers, errors were discovered in SwissPost voting and election verifier.

SwissPost Voting system was disclosed for public review and a number of vulnerabilities were discovered, which are detailed in the report by Haines et al. \cite{Haines2022RunningTR}. One such vulnerability was the system's failure to verify that signatures came from the expected party. This could have allowed integrity attacks by spoofing the ballots of honest election participants. While Swiss Post has announced plans to address the issue, it has not been fully resolved yet. The report recommends checking the identity and key usage during signature verification and ensuring secure initialization of root certificates. Additionally, future versions of the system might want to eliminate certificate chains entirely to avoid the need to trust any root authority.

One of the vulnerabilities in SwissPost voting system lies in the management of discrepancies during the vote confirmation stage. In particular, the logs of various Confirmation Code Returners (CCRs) might not align, providing an opportunity for a attacker to tamper with the system. This weakness can be leveraged in two ways. First, the attacker could provide the valid Vote Cast Return Code to the voter while generating a vote transcript that results in the voter's vote being discarded. Alternatively, the attacker could generate a vote encryption that results in the acceptance of such vote that was made up without using ballot casting key. To address this issue, the authors suggests that the protocol specification should clearly detail how to handle such discrepancies. Additionally, the proof of security have to illustrate this approach to be compatible with the system. The report offers several examples of possible discrepancies and their potential exploitation. It concludes that the existing security proof does not adequately address scenarios like these and advocates for more rigorous verification standards.

The report highlights a possible weak point in the voting system, associated with the absence of Zero-Knowledge (ZK) proofs and accurate key creation. This weak point could risk the system's privacy, as a few parties might be privy to the secret key, which ideally should have been created in a distributed fashion. The document explains a potential attack scenario such that three parties are simultaneously compromised:  voting server, the election board, and one of the online Confirmation Code Makers (CCMs) and are controlled by attacker. The attacker has the ability to alter the public key shares and generate a share that neutralizes the inputs of the trustworthy CCMs. This enables the attacker to gain knowledge of the secret key used for vote encryption, thus breaching privacy. However, the report recognises that this attack is not feasible in the the current security setting of the protocol due to certain protective measures. These include the belief that some members of the electoral board are immune to corruption and that auditors only allow the member of the electoral board to disclose their secret key to the CCM which is offline, following a successful encryption vote mix.

Despite the fact that the SwissPost voting system was supposed to be transparent and verifiable, it demonstrated errors and vulnerabilities. However, using the concept of ``Software Independence" \cite{Rivest2008OnTN}, a conducted election can still be verified as correct, given the correct verifier and assuming that the errors did not occur or the vulnerabilities were not exploited during election. To implement this, the Swiss government introduced an Election Verifier. The following work of Haines et. al. \cite{Haines2020HowNT} analyzes this verifier and finds that it was also seriously flawed, to the extent that it could verify a fraudulent election as correct without recognizing it. Thus, the verifier did not help to ensure the election's integrity but only gave false hope. The election could pass verification even when the votes were manipulated, as the verifier was able to accept fake proofs. The essence of the problem is that the election protocol left a trapdoor for a malicious election administrator to replace the votes during the stage of shuffling the votes \cite{Haines2022RunningTR} and the proposed verifier was not able to detect it.

The e-voting system of SwissPost contains a notable error in the way it applies the Fiat-Shamir heuristic. This error enables a dishonest authority to interfere with the decryption process and create a proof of correct decryption that, while passing verification, declares an incorrect plaintext. The error arises because the proof of correct decryption of a ciphertext doesn't hash the ciphertext. Consequently, a dishonest prover can calculate a valid proof and then select a statement based on that proof. This undermines the validity of the proof and can be taken advantage of by a malicious authority, such as the system's CCM1, to alter specific votes during the decryption process and create decryption proofs that can't be distinguished from legitimate ones, thus passing verification.

The aforementioned security flaw has a couple of constraints. First, to fabricate a decryption proof and successfully complete a shuffle proof, the adversary must have knowledge of the random values used in the encryption of the votes they aim to alter. This could be accomplished either by compromising a voting client or by taking advantage of a weak random number generator. Second, while the malicious entity can't arbitrarily declare a false plaintext and still have the shuffle proof function, they can still demonstrate that a ciphertext decrypts to something other than the actual value, resulting in an output vote that's more likely to be gibberish than a legitimate vote. This manipulation could be used to strategically invalidate votes that the adversary disagrees with, potentially swaying the political balance in their favor.

The verification process is flawed due to its reliance on a premise that has been proven incorrect. As a result, its successful execution doesn't necessarily guarantee accuracy. Although the exploit is likely to leave traces of irregularities, identifying the root cause of the issue could be challenging without infringing on the privacy of certain votes, especially if the identified weakness in the Fiat-Shamir transform is not recognized. To address this, it's recommended that all pertinent data be included in the hash during the application of the Fiat-Shamir heuristic. Currently, steps are being taken to rectify this issue in forthcoming iterations of the system.

The above works highlight the serious consequences that errors in an election verifier can cause. If the developers had used proof-based software development or our proposed technique, such errors might have been avoided. This work underscores the need for accessible techniques for building proven correct election verification tools, such as the one we propose.

\section{Correctness of Electronic Election}
One of the most important aspects of any election is ensuring the correctness of the results. Even in cases where the winner is determined by a simple majority, it is crucial to verify the accuracy of the vote counting process. This stream of work aligns closely with our current project and focuses specifically on election verification.

Pattison et al. \cite{Pattinson2015VoteCA} have emphasized the importance of formal verification in ensuring accurate election results. Their research specifically focuses on the formal verification of final election results.

Pattison et al. \cite{Pattinson2015VoteCA} developed a verified correct election result verifier for majority elections. Their work relied on the concept of ``Software Independence" \cite{Rivest2008OnTN} and used the Coq Theorem Prover to extract code and produce an executable program. However, their work is limited in scope as it only verifies tallying of votes of plaintext elections and did not encompass other universally verifiable election integrity properties, This leaves a gap which we will try to cover. Additionally, they used the Coq theorem prover, whose extraction mechanism is not formally verified. Despite these limitations, their work serves as a significant example and prototype for formal election verification. 

Another noteworthy contribution to election result verification is the work of Ghale et al. \cite{Ghale2018VerifiedCC}, who verified a more complex election type known as the Single Transferable Vote (STV) scheme. While Pattison et al.'s work focused on verifying the tallying of votes for plaintext majority elections, Ghale et al.'s work extends this to a more complex election scheme. Their work demonstrates the feasibility of formal verification in complex elections and provides a valuable contribution to the field of election verification.

The Single Transferable Vote (STV) is a voting technique, intended for multi-seat elections, aiming to achieve proportional representation. In an STV election, voters order candidates based on their preferences. During the tallying phase, if a candidate receives votes exceeding the quota needed to win a seat, the surplus of the votes are given to the other candidates according to the voters' secondary preferences. If no one of the candidates can reach the quota, then the candidate who had received the lowest number of votes is removed, and their votes are reassigned according to the voters' subsequent preferences. This procedure is repeated until all seats are filled, ensuring that the greatest number of votes have an impact on the final election result.

Given that the Single Transferable Vote (STV) type of election involves a more complex tallying process, the verification of vote counting becomes even more crucial than in majority elections. However, the election protocol does not incorporate cryptography, which considerably simplifies the computation. Ghale et al. \cite{Ghale2018VerifiedCC} developed a framework for the verification of election vote counting, utilizing the verified proof assistant HOL and the verified compiler CakeML. These tools enable the creation of an end-to-end correct election verifier \cite{Kumar2014HOLWD, Tan2019TheVC}. They achieved total correctness and developed an end-to-end proven correct verifier for electronic elections. Like the Pattison team, they worked with plaintext election data and verified only vote tallying, not other verifiable properties. Furthermore, Ghale et al.\cite{Ghale2018VerifiedCC}  conducted a trial and verified a real election of substantial size, which increases confidence in the practical usability of formally verified software built using HOL and CakeML. Their work serves as a standalone proof of concept and an excellent prototype of an end-to-end proven correct election verification tool.

Next, we examine the work of \label{Haines} Haines et al. \cite{Haines2019VerifiedVF}, who developed an election verifier for encrypted elections. This work comes close to achieving end-to-end correctness in election verification and, as they state, ``significantly reduced the gap" between correct theory and operational program. Their work includes the development of formal definitions of the elementary components of the verifier and the formal proof of its correctness. The program they developed was capable of verifying the universally verifiable integrity properties of a real election and the proofs of well-formed ballot. Positive aspects of their work is that they used the same code to prove correctness about and compile the executable and worked with encrypted election.

However, a drawback of their work is that the formulation of the Honest Verifier Zero Knowledge theorem does not align with its intended description. While the theorem was intended to establish a bijection between the transcript space and randomness, the mathematical formulation (3.1) of the theorem does not constitute this bijection. Specifically, the authors state: ``We define honest verifier zero knowledge in a concrete way without referring to probabilities; we show that there exists a bijection between the transcripts generated by taking the random coin from the commit in P0 and by taking the response at random in the simulation. In addition we require the challenge space to be an abelian group, the algorithms to output the transcript they receive without change, that algorithm V0 outputs the challenge from its randomness tape without modification, and that the simulator produces accepting transcripts on all inputs" \cite{Haines2019VerifiedVF}. This discrepancy was corrected in their next work.

Mathematical formulation differs from the claim and states precisely as follows, direct citation \cite{Haines2019VerifiedVF}:
\begin{align}
&`` \forall s \in S, \ w \in W,  \ r \in R,  \ e \in E, \nonumber \\
&\text{Rel}(s,w) = \text{true} \Rightarrow \label{eq:1} \nonumber \\
&P_1(V0(P0(s,r,w),e),r,w) = \text{simulator}(s,\text{simMap}(s,r,e,w),e)   \nonumber \\
&\land \forall t \in T, \exists r \in R \text{ s.t. } t = \text{simMap}(s,r,e,w)" \tag{3.1}
\end{align}
Bijection requires:\\
\begin{align}
&f(t) = r \quad \text{and} \quad f^{-1}(r) = t \tag{3.2} 
\end{align} 
Here we can see a map from randomness space to response space \cite{Haines2019VerifiedVF}:\\
\begin{align}
&``t = \text{simMap}(s,r,e,w)" \tag{3.3} 
\end{align}\nonumber \\
Here we do not see, the map from response space to randomness space:
\begin{align}
r = \text{simMap}^{(-1)}(s,t,e,w). \tag{3.4} 
\end{align}\nonumber \\
Furthermore, the researchers employed the Coq proof assistant for their proofs. However, the extraction mechanism of Coq does not guarantee the correct operation of the resulting program according to the proved properties. As a result, the final executable verifier does not come with an absolute guarantee of correctness. This situation leaves a minor gap in software correctness, a gap that our current work aims to address and potentially fill.

This work addresses the discrepancy in the bijection identified in the previous study\cite{Haines2019VerifiedVF}. It is noteworthy for its creation of verified logical components that are crucial in developing elections and verifiers\cite{Haines2021DidYM}. The work provides logical components and proves their correctness. These components are intended for use by election developers to prevent critical errors in elections. The work is primarily relevant to the cryptographic system for electronic elections called mixnets, introduced by Chaum\cite{Chaum1981UntraceableEM}. However, these components are also usable building blocks for constructing election verifiers or implementing election protocols for other electronic elections. One positive aspect of this work is that all essential building blocks are clearly defined and proven correct according to the definition of correct sigma protocol given by \cite{Cramer1997ModularDO}. One downside is that this logical machinery is again developed using Coq, which, as mentioned earlier, does not have a proven correct extraction mechanism. Nonetheless, this work provides valuable material and inspiration for present work. We build upon the developed formulations and compile them using a verified compiler, thereby addressing the issue of the correctness gap.

The corrected version of with Honest Verifier Zero Knowledge theorem formulation with bijection in \cite{Haines2021DidYM}. Direct citation:
\begin{align*}
&\text{{``honest\_verifier\_ZK}} : \forall s \in S, w \in W, e \in E, r \in R, t \in T,  \\
&(\text{{V}}_{1} (\text{{P}}_{1}(\text{{V}}_{0} (\text{{P}}_{0}\ s\ r\ w) e) r w) = \text{{true}}  \\
&\rightarrow (\text{{P}}_{1}(\text{{V}}_{0} (\text{{P}}_{0}\ s\ r\ w) e) r w) = \text{{simulator}}\ s\  (\text{{simMap}}\ s\ w\ e\ r)\ e)  \ \land  \\
&\text{{simMapInv}}\ s\ w\ e\ (\text{{simMap}}\ s\ w\ e\ r) = r  \ \land \\
&\text{{simMap}}\ s\ w\ e\ (\text{{simMapInv}}\ s\ w\ e\ t) = t" \tag{3.5}
\end{align*}
Which does establish a bijection. 


\section{Summary}
Our research is contained within the rapidly developing field of electronic elections and their verification. We have reviewed several papers on topics such as sigma protocol correctness, election protocol design and verifiability, the exposure of errors in electronic elections, and election verification efforts. These studies provide a comprehensive overview of the current state of the industry, highlighting the significant interest and effort invested in achieving reliable and guaranteed correct elections.

The area of election protocol design directly connect to our work. Improvements in election protocol contribute to the definitions of properties that can be verified using a correct verifier. While our current focus is on verifying the universally verifiable integrity property, the defined properties for other election protocols provide avenues for future research. For instance, security or privacy properties could also be verified using a correct verifier.

The importance of our work is underscored by studies exposing errors in electronic elections and verifiers. These demonstrations of vulnerabilities and their consequences underscore the need for a proven correct verifier to guarantee election integrity. Furthermore, work on formalisation reveals the broader applications of sigma protocols beyond elections.

The works of Haines and Ghale \cite{Haines2019VerifiedVF, Ghale2018VerifiedCC} identifies a gap in the existing literature. Haines worked with encrypted election verification using unverified tools and Ghale worked on plaintext election verification with verified tools. There is a lack of work on the verification of encrypted elections using verified tools. We intend to build upon their findings and cover the gap, by providing verification of encrypted elections using verified tools. However,  our research does not merely focus on verifying a single election; instead, we propose a technique along with reusable elementary components for building a proven correct verifier for other encrypted elections.